{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54029be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1763/3482250851.py:44: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embedding_wrapper = HuggingFaceEmbeddings(model_name=embedding_model_id)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[91mYour system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Chroma DB 구축 및 저장\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# documents 리스트가 비어있지 않은 경우에만 DB 구축\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m documents:\n\u001b[0;32m---> 49\u001b[0m     chroma_db \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./chroma_db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     chroma_db\u001b[38;5;241m.\u001b[39mpersist() \u001b[38;5;66;03m# 디렉토리에 DB 파일 저장\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChroma DB가 성공적으로 구축되었습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/langchain_community/vectorstores/chroma.py:878\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    876\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    877\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/langchain_community/vectorstores/chroma.py:814\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    794\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[1;32m    795\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \n\u001b[1;32m    797\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m     chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    824\u001b[0m         ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/langchain_core/_api/deprecation.py:215\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     emit_warning()\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/langchain_community/vectorstores/chroma.py:83\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize with a Chroma client.\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/chromadb/__init__.py:86\u001b[0m\n\u001b[1;32m     84\u001b[0m             sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpysqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     87\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[91mYour system has an unsupported version of sqlite3. Chroma \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124m                    requires sqlite3 >= 3.35.0.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[94mPlease visit \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124m                    https://docs.trychroma.com/troubleshooting#sqlite to learn how \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124m                    to upgrade.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m             )\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconfigure\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override Chroma's default settings, environment variables or .env files\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[91mYour system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.\u001b[0m"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings # HuggingFace Embeddings (Deprecation Warning 가능성 있음)\n",
    "from langchain.llms import HuggingFacePipeline # <-- HuggingFacePipeline 임포트 (LangChain 핵심 또는 community에서)\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline # <-- pipeline 함수 임포트\n",
    "from peft import PeftModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. CSV에서 `short_prompt`, `long_prompt` 로드\n",
    "# 사용자 환경에 맞는 파일 경로로 수정해주세요.\n",
    "df = pd.read_csv(\"/app/workspace/data/data9000_forRAG_test .csv\")\n",
    "\n",
    "# 2. E5 임베딩 모델 로드 및 `long_prompt` 벡터화\n",
    "embedding_model_id = \"intfloat/multilingual-e5-large\" # E5 임베딩 모델 ID\n",
    "# sentence_transformers 라이브러리로 모델 로드\n",
    "embedder = SentenceTransformer(embedding_model_id)\n",
    "\n",
    "# long_prompt 앞에 \"passage:\" 붙여서 벡터화 준비\n",
    "passages = [\"passage: \" + p for p in df[\"prompt\"].dropna()] # 결측치 제거 후 처리\n",
    "# long_prompt가 비어있는 경우(NaN) 오류 방지\n",
    "# embeddings = embedder.encode(passages, show_progress_bar=True, batch_size=32) # 오류 발생 시 passes->passages\n",
    "\n",
    "# 3. Chroma 벡터 DB 저장\n",
    "# long_prompt가 비어있는 행은 문서 생성에서 제외\n",
    "# documents = [\n",
    "#     Document(page_content=row[\"prompt\"], metadata={\"short_prompt\": row[\"short_prompt\"]})\n",
    "#     for _, row in df.dropna(subset=[\"prompt\"]).iterrows() # long_prompt에 결측치 없는 행만 사용\n",
    "# ]\n",
    "\n",
    "# Chroma에 긴 영어 프롬프트만 넣기\n",
    "documents = [\n",
    "    Document(page_content=row[\"prompt\"]) # metadata 제외\n",
    "    for _, row in df.dropna(subset=[\"prompt\"]).iterrows()\n",
    "]\n",
    "\n",
    "# LangChain에서 HuggingFace 임베딩 래퍼 사용\n",
    "# Deprecation Warning이 뜬다면 from langchain_huggingface.embeddings import HuggingFaceEmbeddings 사용 권장\n",
    "embedding_wrapper = HuggingFaceEmbeddings(model_name=embedding_model_id)\n",
    "\n",
    "# Chroma DB 구축 및 저장\n",
    "# documents 리스트가 비어있지 않은 경우에만 DB 구축\n",
    "if documents:\n",
    "    chroma_db = Chroma.from_documents(documents, embedding_wrapper, persist_directory=\"./chroma_db\")\n",
    "    chroma_db.persist() # 디렉토리에 DB 파일 저장\n",
    "    print(\"Chroma DB가 성공적으로 구축되었습니다.\")\n",
    "else:\n",
    "    # 이미 DB가 저장되어 있다면 로드하여 사용하거나, 문서를 다시 확인해야 합니다.\n",
    "    # 여기서는 문서가 없을 경우 메시지만 출력하고 Retriever는 None으로 둡니다.\n",
    "    print(\"long_prompt 컬럼에 유효한 데이터가 없습니다. DB 구축을 건너뜁니다.\")\n",
    "    # 만약 저장된 DB를 로드하고 싶다면 아래 주석을 해제하고 경로를 확인하세요.\n",
    "    # embedding_wrapper가 필요하므로 다시 정의해야 합니다.\n",
    "    # embedding_wrapper = HuggingFaceEmbeddings(model_name=embedding_model_id)\n",
    "    # try:\n",
    "    #     chroma_db = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_wrapper)\n",
    "    #     print(\"기존 Chroma DB를 로드했습니다.\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"기존 DB 로드 실패: {e}\")\n",
    "    #     chroma_db = None # 로드 실패 시 None\n",
    "\n",
    "# 4. Chroma 벡터 DB에서 유사한 `long_prompt`를 검색할 수 있게 설정\n",
    "retriever = None\n",
    "if chroma_db is not None:\n",
    "    retriever = chroma_db.as_retriever(search_kwargs={\"k\": 3}) # k=3으로 상위 3개 유사 프롬프트 검색\n",
    "    print(\"Retriever 설정 완료.\")\n",
    "else:\n",
    "    print(\"Chroma DB가 없어 Retriever를 설정할 수 없습니다.\")\n",
    "\n",
    "\n",
    "# 5. Kanana 모델 로드 (HuggingFacePipeline 사용 준비)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_skip_modules=None,\n",
    "    llm_int8_enable_fp32_cpu_offload=True # 핵심!\n",
    ")\n",
    "\n",
    "# 사용자 환경에 맞는 모델/어댑터 경로로 수정해주세요.\n",
    "adapter_path = \"/home/piai/workspace/Kanana_Prompt5000/outputs\"\n",
    "base_model_id = \"kakaocorp/kanana-nano-2.1b-instruct\" # 베이스 모델 ID\n",
    "\n",
    "print(f\"Base 모델 로딩: {base_model_id}...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "print(\"Base 모델 로딩 완료.\")\n",
    "\n",
    "print(f\"LoRA 어댑터 로딩: {adapter_path}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33835d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. LoRA 어댑터 붙이기\n",
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "model.eval()\n",
    "print(\"LoRA 어댑터 로딩 완료.\")\n",
    "\n",
    "print(f\"Tokenizer 로딩: {adapter_path}...\")\n",
    "# 7. Tokenizer 불러오기\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_path, use_fast=False)\n",
    "print(\"Tokenizer 로딩 완료.\")\n",
    "\n",
    "\n",
    "# 8. LangChain에서 사용할 Kanana 모델 설정 (HuggingFacePipeline 사용)\n",
    "\n",
    "# Hugging Face Pipeline 객체 생성\n",
    "# 로드한 model과 tokenizer를 pipeline에 연결하고 생성 파라미터 설정\n",
    "print(\"HuggingFace Pipeline 설정 중...\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", # 수행할 작업 (텍스트 생성)\n",
    "    model=model, # 로드된 PeftModel (LoRA 적용된 모델)\n",
    "    tokenizer=tokenizer, # 로드된 Tokenizer\n",
    "    max_new_tokens=300, # 생성될 최대 토큰 수 (generate 함수의 인자와 동일)\n",
    "    max_length=500, # 파이프라인의 최대 길이 설정\n",
    "    do_sample=False, # generate 함수의 인자와 동일\n",
    "    repetition_penalty=1.5, # generate 함수의 인자와 동일\n",
    "    eos_token_id=tokenizer.eos_token_id, # generate 함수의 인자와 동일\n",
    "    pad_token_id=tokenizer.pad_token_id, # generate 함수의 인자와 동일\n",
    "    num_return_sequences=1, # generate 함수의 인자와 동일\n",
    "    no_repeat_ngram_size=2, # generate 함수의 인자와 동일\n",
    "#     device=0 # 또는 \"cuda\". 모델이 이미 GPU에 로드되었다면 명시적으로 지정. CPU 사용 시 -1 또는 \"cpu\"\n",
    ")\n",
    "print(\"HuggingFace Pipeline 설정 완료.\")\n",
    "\n",
    "# HuggingFacePipeline 래퍼 생성\n",
    "# 생성한 pipeline 객체를 HuggingFacePipeline 클래스에 전달\n",
    "kanana_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "print(\"LangChain LLM 객체 (kanana_llm) 준비 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 프롬프트 템플릿 구성 (검색된 `long_prompt` + 사용자 `short_prompt`)\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a Midjourney prompt generator.\n",
    "Refer to the following examples and rewrite the given simple idea into a detailed English prompt.\n",
    "\n",
    "[Examples]\n",
    "{context}\n",
    "\n",
    "[User Input]\n",
    "{question}\n",
    "\n",
    "[Prompt]\n",
    "\"\"\"\n",
    ")\n",
    "print(\"프롬프트 템플릿 설정 완료.\")\n",
    "\n",
    "# 10. RAG 체인 구성 (검색된 `long_prompt`와 사용자 `short_prompt` 결합)\n",
    "rag_chain = None\n",
    "if retriever is not None:\n",
    "    print(\"RAG 체인 설정 중...\")\n",
    "    rag_chain = RetrievalQA.from_chain_type(\n",
    "        llm=kanana_llm, # <-- 여기서 HuggingFacePipeline 객체를 사용합니다.\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": prompt_template}\n",
    "    )\n",
    "    print(\"RAG 체인 설정 완료.\")\n",
    "else:\n",
    "    print(\"Retriever가 없어 RAG 체인을 설정할 수 없습니다.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bbe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. 사용자 `short_prompt`로 Kanana에 전달하여 최종 long_prompt 생성\n",
    "user_input = \"하늘을 나는 고양이를 그려줘\" # 예시 사용자 입력\n",
    "if rag_chain is not None:\n",
    "    print(f\"\\n사용자 입력: {user_input}\")\n",
    "    print(\"Kanana 모델로 long_prompt 생성 중...\")\n",
    "    response = rag_chain.run(user_input)\n",
    "\n",
    "    # 12. 결과 출력\n",
    "    print(\"\\n--- 생성된 long_prompt ---\")\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"\\nRAG 체인이 설정되지 않아 long_prompt를 생성할 수 없습니다. Chroma DB 구축/로드 상태를 확인하세요.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
